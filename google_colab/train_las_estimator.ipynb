{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp-sxdH_WdVL",
    "colab_type": "text"
   },
   "source": [
    "# Puesta a punto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiHlKPOlZHCS",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "\n",
    "## Instalación de paquetes necesarios\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PtkPd7YoWZLl",
    "colab_type": "code",
    "outputId": "e8c184a9-2fb6-47fa-83cb-8689bbb77d73",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.553559050399E12,
     "user_tz": 180.0,
     "elapsed": 9365.0,
     "user": {
      "displayName": "Nicolás Zorzano",
      "photoUrl": "",
      "userId": "08235469428832012461"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features\n",
      "Successfully installed python-speech-features-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python_speech_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn5bgHjdWxSM",
    "colab_type": "text"
   },
   "source": [
    "## Preparación del entorno para poder correr mis módulos importados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yOE4tgZsW1et",
    "colab_type": "code",
    "outputId": "a65f90a9-3607-46da-b31a-e85ec6c44bce",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.553559075158E12,
     "user_tz": 180.0,
     "elapsed": 31796.0,
     "user": {
      "displayName": "Nicolás Zorzano",
      "photoUrl": "",
      "userId": "08235469428832012461"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2344332101687675252, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8266229863755046234\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 6002542210046975738\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11276946637\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5711462065763696766\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import sys\n",
    "sys.path.append('drive/My Drive/Tesis')\n",
    "sys.path.append('drive/My Drive/Tesis/repo')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_1mN3rHXqLT",
    "colab_type": "text"
   },
   "source": [
    "# Entrenamiento de LASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh1DAAWCXygf",
    "colab_type": "text"
   },
   "source": [
    "## Importación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "itKOqreUX1gK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.utils.Database import Database\n",
    "from src.utils.LASLabel import LASLabel\n",
    "from src.utils.ProjectData import ProjectData\n",
    "import time\n",
    "from src.neural_network.LAS.LASNetData import LASNetData\n",
    "import pprint\n",
    "from src.Estimators.las.model_fn import model_fn\n",
    "from src.Estimators.las.data_input_fn import data_input_fn\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K73_jDd7X_CO",
    "colab_type": "text"
   },
   "source": [
    "## Definición de los hiperparámetros de la red\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ROoJRMZwX-at",
    "colab_type": "code",
    "outputId": "6622da9a-02b1-4f32-9da6-7248b9cd50fa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.553559091787E12,
     "user_tz": 180.0,
     "elapsed": 703.0,
     "user": {
      "displayName": "Nicolás Zorzano",
      "photoUrl": "",
      "userId": "08235469428832012461"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_activation': <function tanh at 0x7fbba0aa1840>,\n",
      " 'attention_keep_prob': 0.8,\n",
      " 'attention_num_layers': 1,\n",
      " 'attention_size': None,\n",
      " 'attention_type': 'luong',\n",
      " 'attention_units': 256,\n",
      " 'batch_normalization_1': True,\n",
      " 'batch_normalization_2': True,\n",
      " 'beam_width': 0,\n",
      " 'bias_init_1': [<tensorflow.python.ops.init_ops.Zeros object at 0x7fbb93b6b898>,\n",
      "                 <tensorflow.python.ops.init_ops.Zeros object at 0x7fbb93b6b898>],\n",
      " 'bias_init_2': [<tensorflow.python.ops.init_ops.Zeros object at 0x7fbb93b6b860>],\n",
      " 'checkpoint_path': 'drive/My '\n",
      "                    'Drive/Tesis/repo/out/las_net/checkpoint/model.ckpt',\n",
      " 'dense_activations_1': [<function relu at 0x7fbba08ca840>,\n",
      "                         <function relu at 0x7fbba08ca840>],\n",
      " 'dense_activations_2': [<function relu at 0x7fbba08ca840>],\n",
      " 'eos_id': 2,\n",
      " 'keep_prob_1': [0.7, 0.7],\n",
      " 'keep_prob_2': [0.7],\n",
      " 'kernel_init_1': [<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7fbb93b6b8d0>,\n",
      "                   <tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7fbb93b6b8d0>],\n",
      " 'kernel_init_2': [<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7fbb93b6b940>],\n",
      " 'kernel_regularizer': 0.0,\n",
      " 'listener_activation_list': [<function tanh at 0x7fbba0aa1840>],\n",
      " 'listener_keep_prob_list': [0.8],\n",
      " 'listener_num_layers': 1,\n",
      " 'listener_num_units': [256],\n",
      " 'model_path': 'drive/My Drive/Tesis/repo/out/las_net/model/model',\n",
      " 'num_classes': 30,\n",
      " 'num_dense_layers_1': 2,\n",
      " 'num_dense_layers_2': 1,\n",
      " 'num_embeddings': 0,\n",
      " 'num_features': 494,\n",
      " 'num_units_1': [400, 400],\n",
      " 'num_units_2': [300],\n",
      " 'optimizer': <tensorflow.python.training.adam.AdamOptimizer object at 0x7fbb93b6b908>,\n",
      " 'sampling_probability': 0.2,\n",
      " 'sos_id': 1,\n",
      " 'tensorboard_path': 'drive/My Drive/Tesis/repo/out/las_net/tensorboard/'}\n"
     ]
    }
   ],
   "source": [
    "# Load project data\n",
    "project_data = ProjectData()\n",
    "\n",
    "network_data = LASNetData()\n",
    "network_data.model_path = 'drive/My Drive/Tesis/repo/' + project_data.LAS_NET_MODEL_PATH\n",
    "network_data.checkpoint_path = 'drive/My Drive/Tesis/repo/' + project_data.LAS_NET_CHECKPOINT_PATH\n",
    "network_data.tensorboard_path = 'drive/My Drive/Tesis/repo/' + project_data.LAS_NET_TENSORBOARD_PATH\n",
    "\n",
    "network_data.num_classes = LASLabel.num_classes\n",
    "network_data.num_features = 494\n",
    "network_data.num_embeddings = 0\n",
    "network_data.sos_id = LASLabel.SOS_INDEX\n",
    "network_data.eos_id = LASLabel.EOS_INDEX\n",
    "\n",
    "network_data.beam_width = 0\n",
    "\n",
    "network_data.num_dense_layers_1 = 2\n",
    "network_data.num_units_1 = [400] * network_data.num_dense_layers_1\n",
    "network_data.dense_activations_1 = [tf.nn.relu] * network_data.num_dense_layers_1\n",
    "network_data.batch_normalization_1 = True\n",
    "network_data.keep_prob_1 = [0.7] * network_data.num_dense_layers_1\n",
    "network_data.kernel_init_1 = [tf.truncated_normal_initializer(mean=0, stddev=0.1)] * network_data.num_dense_layers_1\n",
    "network_data.bias_init_1 = [tf.zeros_initializer()] * network_data.num_dense_layers_1\n",
    "\n",
    "network_data.listener_num_layers = 1\n",
    "network_data.listener_num_units = [256] * network_data.listener_num_layers\n",
    "network_data.listener_activation_list = [tf.nn.tanh] * network_data.listener_num_layers\n",
    "network_data.listener_keep_prob_list = [0.8] * network_data.listener_num_layers\n",
    "\n",
    "network_data.num_dense_layers_2 = 1\n",
    "network_data.num_units_2 = [300]\n",
    "network_data.dense_activations_2 = [tf.nn.relu] * network_data.num_dense_layers_2\n",
    "network_data.batch_normalization_2 = True\n",
    "network_data.keep_prob_2 = [0.7] * network_data.num_dense_layers_2\n",
    "network_data.kernel_init_2 = [tf.truncated_normal_initializer(mean=0, stddev=0.1)] * network_data.num_dense_layers_2\n",
    "network_data.bias_init_2 = [tf.zeros_initializer()] * network_data.num_dense_layers_2\n",
    "\n",
    "network_data.attention_type = 'luong'       # 'luong', 'bahdanau'\n",
    "network_data.attention_num_layers = 1\n",
    "network_data.attention_size = None\n",
    "network_data.attention_units = 256\n",
    "network_data.attention_activation = tf.nn.tanh\n",
    "network_data.attention_keep_prob = 0.8\n",
    "\n",
    "network_data.kernel_regularizer = 0.0\n",
    "network_data.sampling_probability = 0.2\n",
    "\n",
    "network_data.optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "pprint.pprint(network_data.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gcx3G_kpnXAn",
    "colab_type": "text"
   },
   "source": [
    "# Configuración del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "WjKvq3hqnej7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from src.Estimators.las.data_input_fn import data_input_fn\n",
    "\n",
    "\n",
    "# def data_input_fn(filenames, batch_size, parse_fn, shuffle_buffer, num_features, sos_id, eos_id, num_epochs=1):\n",
    "# #     return data_input_fn(filenames, batch_size, parse_fn, shuffle_buffer, num_features, sos_id, eos_id, num_epochs)\n",
    "#     dataset = tf.data.TFRecordDataset(filenames)\n",
    "#     dataset = dataset.map(parse_fn)\n",
    "\n",
    "#     dataset = dataset.map(\n",
    "#         lambda feature, target, feat_len, target_len: (feature,\n",
    "#                                                        tf.concat(([sos_id], target), 0),\n",
    "#                                                        tf.concat((target, [eos_id]), 0),\n",
    "#                                                        feat_len,\n",
    "#                                                        target_len)\n",
    "#     )\n",
    "\n",
    "#     dataset = dataset.map(\n",
    "#         lambda feature, target_in, target_out, feat_len, target_len: (feature,\n",
    "#                                                                       target_in,\n",
    "#                                                                       target_out,\n",
    "#                                                                       feat_len,\n",
    "#                                                                       tf.size(target_in, out_type=tf.int64)))\n",
    "\n",
    "#     # dataset = dataset.map(\n",
    "#     #     lambda feature, target_in, target_out, feat_len, target_len: (feature,\n",
    "#     #                                                                   tf.cast(target_in, tf.int32),\n",
    "#     #                                                                   tf.cast(target_out, tf.int32),\n",
    "#     #                                                                   tf.cast(feat_len, dtype=tf.int32),\n",
    "#     #                                                                   tf.cast(target_len, dtype=tf.int32)\n",
    "#     #                                                                   )\n",
    "#     # )\n",
    "\n",
    "#     dataset = dataset.padded_batch(\n",
    "#         batch_size=batch_size,\n",
    "#         padded_shapes=((None, num_features), [None], [None], (), ()),\n",
    "#         padding_values=(tf.constant(value=0, dtype=tf.float32),\n",
    "#                         tf.constant(value=eos_id, dtype=tf.int64),\n",
    "#                         tf.constant(value=eos_id, dtype=tf.int64),\n",
    "#                         tf.constant(value=0, dtype=tf.int64),\n",
    "#                         tf.constant(value=0, dtype=tf.int64),\n",
    "#                         )\n",
    "#     )\n",
    "#     dataset = dataset.shuffle(shuffle_buffer).repeat(num_epochs)\n",
    "\n",
    "#     # return dataset\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "#     next_element = iterator.get_next()\n",
    "\n",
    "#     feature, target_in, target_out, feat_len, target_len = next_element\n",
    "\n",
    "#     feat_len = tf.cast(feat_len, dtype=tf.int32)\n",
    "#     target_in = tf.cast(target_in, tf.int32)\n",
    "#     target_out = tf.cast(target_out, tf.int32)\n",
    "#     target_len = tf.cast(target_len, tf.int32)\n",
    "\n",
    "#     return {'feature': feature, 'feat_len': feat_len}, \\\n",
    "#            {'targets_outputs': target_out, 'targets_inputs': target_in, 'target_len': target_len}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAjWeU9ynno6",
    "colab_type": "text"
   },
   "source": [
    "# Configuración del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "LrLWDuWhnquJ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.neural_network.network_utils import bidirectional_pyramidal_rnn, attention_layer, attention_decoder, \\\n",
    "    beam_search_decoder, greedy_decoder, edit_distance, attention_loss, dense_multilayer\n",
    "from src.Estimators.las.model_fn import model_fn\n",
    "\n",
    "\n",
    "# def model_fn(features,\n",
    "#              labels,\n",
    "#              mode,\n",
    "#              params):\n",
    "# #   return model_fn(features, labels, mode, params)\n",
    "\n",
    "#     input_features = features['feature']\n",
    "#     input_features_length = features['feat_len']\n",
    "\n",
    "#     decoder_inputs = None\n",
    "#     targets = None\n",
    "#     targets_length = None\n",
    "\n",
    "#     if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#         decoder_inputs = labels['targets_inputs']\n",
    "#         targets = labels['targets_outputs']\n",
    "#         targets_length = labels['target_len']\n",
    "\n",
    "#     with tf.name_scope(\"dense_layer_1\"):\n",
    "#         input_features = dense_multilayer(input_ph=input_features,\n",
    "#                                           num_layers=params['num_dense_layers_1'],\n",
    "#                                           num_units=params['num_units_1'],\n",
    "#                                           name='dense_layer_1',\n",
    "#                                           activation_list=params['dense_activations_1'],\n",
    "#                                           use_batch_normalization=params['batch_normalization_1'],\n",
    "#                                           train_ph=mode == tf.estimator.ModeKeys.TRAIN,\n",
    "#                                           use_tensorboard=True,\n",
    "#                                           keep_prob_list=params['keep_prob_1'],\n",
    "#                                           kernel_initializers=params['kernel_init_1'],\n",
    "#                                           bias_initializers=params['bias_init_1'],\n",
    "#                                           tensorboard_scope='dense_layer_1')\n",
    "\n",
    "#     with tf.variable_scope('listener'):\n",
    "#         listener_output, input_features_length, listener_state = bidirectional_pyramidal_rnn(\n",
    "#             input_ph=input_features,\n",
    "#             seq_len_ph=input_features_length,\n",
    "#             num_layers=params['listener_num_layers'],\n",
    "#             num_units=params['listener_num_units'],\n",
    "#             name=\"listener\",\n",
    "#             activation_list=params['listener_activation_list'],\n",
    "#             use_tensorboard=True,\n",
    "#             tensorboard_scope=\"listener\",\n",
    "#             keep_prob=params['listener_keep_prob_list'],\n",
    "#             train_ph=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "#     with tf.name_scope(\"dense_layer_2\"):\n",
    "#         listener_output = dense_multilayer(input_ph=listener_output,\n",
    "#                                            num_layers=params['num_dense_layers_2'],\n",
    "#                                            num_units=params['num_units_2'],\n",
    "#                                            name='dense_layer_2',\n",
    "#                                            activation_list=params['dense_activations_2'],\n",
    "#                                            use_batch_normalization=params['batch_normalization_2'],\n",
    "#                                            train_ph=mode == tf.estimator.ModeKeys.TRAIN,\n",
    "#                                            use_tensorboard=True,\n",
    "#                                            keep_prob_list=params['keep_prob_2'],\n",
    "#                                            kernel_initializers=params['kernel_init_2'],\n",
    "#                                            bias_initializers=params['bias_init_2'],\n",
    "#                                            tensorboard_scope='dense_layer_2')\n",
    "\n",
    "#     with tf.variable_scope('tile_batch'):\n",
    "#         batch_size = tf.shape(listener_output)[0]\n",
    "#         if mode == tf.estimator.ModeKeys.PREDICT and params['beam_width'] > 0:\n",
    "#             listener_output = tf.contrib.seq2seq.tile_batch(\n",
    "#                 listener_output, multiplier=params['beam_width'])\n",
    "#             input_features_length = tf.contrib.seq2seq.tile_batch(\n",
    "#                 input_features_length, multiplier=params['beam_width'])\n",
    "#             listener_state = tf.contrib.seq2seq.tile_batch(\n",
    "#                 listener_state, multiplier=params['beam_width'])\n",
    "#             batch_size = batch_size * params['beam_width']\n",
    "\n",
    "#     with tf.variable_scope('attention'):\n",
    "#         attention_cell, attention_state = attention_layer(\n",
    "#             input=listener_output,\n",
    "#             lengths=input_features_length,\n",
    "#             num_layers=params['attention_num_layers'],\n",
    "#             attention_units=params['attention_units'],\n",
    "#             attention_size=params['attention_size'],\n",
    "#             attention_type=params['attention_type'],\n",
    "#             activation=params['attention_activation'],\n",
    "#             keep_prob=params['attention_keep_prob'],\n",
    "#             train_ph=mode == tf.estimator.ModeKeys.TRAIN,\n",
    "#             batch_size=batch_size,\n",
    "#             input_state=None,\n",
    "#             use_tensorboard=True,\n",
    "#             tensorboard_scope='attention_cell'\n",
    "#         )\n",
    "\n",
    "#     with tf.variable_scope('speller'):\n",
    "#         def embedding_fn(ids):\n",
    "#             if params['num_embeddings'] != 0:\n",
    "#                 target_embedding = tf.get_variable(\n",
    "#                     name='target_embedding',\n",
    "#                     shape=[params['num_classes'], params['num_embeddings']],\n",
    "#                     dtype=tf.float32,\n",
    "#                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "#                 return tf.nn.embedding_lookup(target_embedding, ids)\n",
    "#             else:\n",
    "#                 return tf.one_hot(ids, params['num_classes'])\n",
    "\n",
    "#         projection_layer = tf.layers.Dense(params['num_classes'], use_bias=True, name='projection_layer')\n",
    "\n",
    "#         maximum_iterations = None\n",
    "#         if mode != tf.estimator.ModeKeys.TRAIN:\n",
    "#             max_source_length = tf.reduce_max(input_features_length)\n",
    "#             maximum_iterations = tf.to_int32(tf.round(tf.to_float(max_source_length) * 2))\n",
    "\n",
    "#         if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#             decoder_inputs = embedding_fn(decoder_inputs)\n",
    "\n",
    "#             decoder = attention_decoder(\n",
    "#                 input_cell=attention_cell,\n",
    "#                 initial_state=attention_state,\n",
    "#                 embedding_fn=embedding_fn,\n",
    "#                 seq_embedding=decoder_inputs,\n",
    "#                 seq_embedding_len=targets_length,\n",
    "#                 projection_layer=projection_layer,\n",
    "#                 sampling_prob=params['sampling_probability'])\n",
    "\n",
    "#         elif mode == tf.estimator.ModeKeys.PREDICT and params['beam_width'] > 0:\n",
    "#             decoder = beam_search_decoder(\n",
    "#                 input_cell=attention_cell,\n",
    "#                 embedding=embedding_fn,\n",
    "#                 start_token=params['sos_id'],\n",
    "#                 end_token=params['eos_id'],\n",
    "#                 initial_state=attention_state,\n",
    "#                 beam_width=params['beam_width'],\n",
    "#                 projection_layer=projection_layer,\n",
    "#                 batch_size=batch_size)\n",
    "#         else:\n",
    "\n",
    "#             decoder = greedy_decoder(\n",
    "#                 inputs=attention_cell,\n",
    "#                 embedding=embedding_fn,\n",
    "#                 start_token=params['sos_id'],\n",
    "#                 end_token=params['eos_id'],\n",
    "#                 initial_state=attention_state,\n",
    "#                 projection_layer=projection_layer,\n",
    "#                 batch_size=batch_size)\n",
    "\n",
    "#         decoder_outputs, final_context_state, final_sequence_length = tf.contrib.seq2seq.dynamic_decode(\n",
    "#             decoder, maximum_iterations=maximum_iterations)\n",
    "\n",
    "#     with tf.name_scope('prediction'):\n",
    "#         if mode == tf.estimator.ModeKeys.PREDICT and params['beam_width'] > 0:\n",
    "#             logits = tf.no_op()\n",
    "#             sample_ids = decoder_outputs.predicted_ids\n",
    "#         else:\n",
    "#             logits = decoder_outputs.rnn_output\n",
    "#             sample_ids = tf.to_int32(tf.argmax(logits, -1))\n",
    "\n",
    "#     if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#         predictions = {'sample_ids': sample_ids}\n",
    "\n",
    "#         return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "#     with tf.name_scope('metrics'):\n",
    "#         ler = edit_distance(\n",
    "#             sample_ids, targets, params['eos_id'], None) #params.mapping)\n",
    "\n",
    "#         metrics = {'LER': tf.metrics.mean(ler),}\n",
    "\n",
    "#     tf.summary.scalar('LER', metrics['LER'][1])\n",
    "\n",
    "#     with tf.name_scope('loss'):\n",
    "#         kernel_loss = 0\n",
    "#         for var in tf.trainable_variables():\n",
    "#             if var.name.startswith('dense_layer') and 'kernel' in var.name:\n",
    "#                 kernel_loss += tf.nn.l2_loss(var)\n",
    "\n",
    "#         attetion_loss = attention_loss(\n",
    "#             logits=logits,\n",
    "#             targets=targets,\n",
    "#             logits_length=final_sequence_length,\n",
    "#             targets_length=targets_length,\n",
    "#             eos_id=params['eos_id'],\n",
    "#             train_ph=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "#         loss = attetion_loss + params['kernel_regularizer'] * kernel_loss\n",
    "\n",
    "#     if mode == tf.estimator.ModeKeys.EVAL:\n",
    "#         # with tf.name_scope('alignment'):\n",
    "#         #     attention_images = utils.create_attention_images(\n",
    "#         #         final_context_state)\n",
    "\n",
    "#         # attention_summary = tf.summary.image(\n",
    "#         #     'attention_images', attention_images)\n",
    "\n",
    "#         # eval_summary_hook = tf.train.SummarySaverHook(\n",
    "#         #     save_steps=10,\n",
    "#         #     output_dir=os.path.join(config.model_dir, 'eval'),\n",
    "#         #     summary_op=attention_summary)\n",
    "\n",
    "#         logging_hook = tf.train.LoggingTensorHook(\n",
    "#             tensors={\n",
    "#                 'LER': tf.reduce_mean(ler),\n",
    "#                 #'max_predictions': sample_ids[tf.argmax(ler)],\n",
    "#                 #'max_targets': targets[tf.argmax(ler)],\n",
    "#             },\n",
    "#             every_n_iter=10)\n",
    "\n",
    "#         return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics, evaluation_hooks=[logging_hook])\n",
    "\n",
    "#     with tf.name_scope('train'):\n",
    "#         optimizer = params['optimizer']\n",
    "#         # optimizer = tf.train.AdamOptimizer(params.learning_rate)\n",
    "#         train_op = optimizer.minimize(\n",
    "#             loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "#     logging_hook = tf.train.LoggingTensorHook(\n",
    "#         tensors={\n",
    "#             'loss': loss,\n",
    "#             'LER': tf.reduce_mean(ler)},\n",
    "#         every_n_secs=10)\n",
    "\n",
    "#     return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, training_hooks=[logging_hook])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi_FGeToYX5k",
    "colab_type": "text"
   },
   "source": [
    "## Configuración de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VnVktYkdYct3",
    "colab_type": "code",
    "outputId": "ad208b82-ab76-401e-bf3f-d06f45edbea4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.553559135636E12,
     "user_tz": 180.0,
     "elapsed": 716.0,
     "user": {
      "displayName": "Nicolás Zorzano",
      "photoUrl": "",
      "userId": "08235469428832012461"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'drive/My Drive/Tesis/repo/out/las_net/estimator/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbb93b6b240>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'drive/My Drive/Tesis/repo/out/las_net/estimator/'\n",
    "\n",
    "base_path = 'drive/My Drive/Tesis/repo/data/tfrecords/librispeech/las/ds_dataset/'\n",
    "\n",
    "index_files = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]#, 15, 16, 17, 18, 19, 20, 21]\n",
    "train_files = ['train_database_{}.tfrecords'.format(item) for item in index_files]\n",
    "val_files = ['test_database_1.tfrecords', 'test_database_2.tfrecords']\n",
    "test_files = ['test_database_2.tfrecords']\n",
    "\n",
    "train_files = list(map(lambda x: base_path + x, train_files))\n",
    "val_files = list(map(lambda x: base_path + x, val_files))\n",
    "test_files = list(map(lambda x: base_path + x, test_files))\n",
    "\n",
    "train_batch_size = 100\n",
    "train_epochs = 1000\n",
    "\n",
    "validate_batch_size = 100\n",
    "\n",
    "restore_run = True\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=model_dir,\n",
    "    save_checkpoints_steps=100,\n",
    "    save_summary_steps=100,\n",
    "    log_step_count_steps=100)\n",
    "\n",
    "\n",
    "model = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    params=network_data.as_dict(),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if not restore_run:\n",
    "    shutil.rmtree(model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeo7ijNFZcdx",
    "colab_type": "text"
   },
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q28RImgUvX60",
    "colab_type": "text"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rYcvBQsDZe-G",
    "colab_type": "code",
    "outputId": "c5a9f131-35f9-4742-eb74-1d42bc5ee81f",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.553555228356E12,
     "user_tz": 180.0,
     "elapsed": 1404469.0,
     "user": {
      "displayName": "Nicolás Zorzano",
      "photoUrl": "",
      "userId": "08235469428832012461"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2026.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from drive/My Drive/Tesis/repo/out/las_net/estimator/model.ckpt-286\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 286 into drive/My Drive/Tesis/repo/out/las_net/estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5610135, step = 286\n",
      "INFO:tensorflow:LER = 0.8675544, loss = 2.5610135\n",
      "INFO:tensorflow:LER = 0.87648565, loss = 2.5647058 (24.646 sec)\n",
      "INFO:tensorflow:LER = 0.7996581, loss = 2.5664563 (22.840 sec)\n",
      "INFO:tensorflow:LER = 0.8982411, loss = 2.5689673 (22.775 sec)\n",
      "INFO:tensorflow:LER = 0.91725177, loss = 2.544212 (22.860 sec)\n",
      "INFO:tensorflow:LER = 1.0375097, loss = 2.5524702 (22.143 sec)\n",
      "INFO:tensorflow:LER = 0.84421897, loss = 2.553715 (22.605 sec)\n",
      "INFO:tensorflow:LER = 0.8021975, loss = 2.5535512 (22.433 sec)\n",
      "INFO:tensorflow:LER = 0.848453, loss = 2.5739028 (22.446 sec)\n",
      "INFO:tensorflow:LER = 0.7909251, loss = 2.562093 (22.040 sec)\n",
      "INFO:tensorflow:LER = 0.7755789, loss = 2.559267 (22.993 sec)\n",
      "INFO:tensorflow:LER = 0.8047525, loss = 2.5426283 (22.542 sec)\n",
      "INFO:tensorflow:LER = 0.9250534, loss = 2.5649395 (21.911 sec)\n",
      "INFO:tensorflow:LER = 0.9522662, loss = 2.5597615 (22.854 sec)\n",
      "INFO:tensorflow:LER = 0.90360284, loss = 2.5401764 (22.286 sec)\n",
      "INFO:tensorflow:LER = 0.89491785, loss = 2.5474255 (22.226 sec)\n",
      "INFO:tensorflow:LER = 0.8731795, loss = 2.5347571 (22.114 sec)\n",
      "INFO:tensorflow:LER = 0.88033134, loss = 2.5510879 (22.508 sec)\n",
      "INFO:tensorflow:LER = 1.0093256, loss = 2.553036 (22.903 sec)\n",
      "INFO:tensorflow:LER = 0.78813136, loss = 2.537621 (22.392 sec)\n",
      "INFO:tensorflow:LER = 1.0186154, loss = 2.5512028 (22.728 sec)\n",
      "INFO:tensorflow:LER = 0.8110572, loss = 2.5472517 (22.191 sec)\n",
      "INFO:tensorflow:LER = 0.85690796, loss = 2.548471 (22.252 sec)\n",
      "INFO:tensorflow:LER = 0.8534034, loss = 2.5512426 (22.578 sec)\n",
      "INFO:tensorflow:LER = 0.79796296, loss = 2.533348 (21.909 sec)\n",
      "INFO:tensorflow:LER = 0.8461006, loss = 2.5436394 (22.546 sec)\n",
      "INFO:tensorflow:LER = 0.8531243, loss = 2.536404 (22.491 sec)\n",
      "INFO:tensorflow:LER = 0.9248922, loss = 2.541241 (22.274 sec)\n",
      "INFO:tensorflow:LER = 0.8407587, loss = 2.5535002 (22.527 sec)\n",
      "INFO:tensorflow:LER = 0.7513987, loss = 2.5434115 (22.422 sec)\n",
      "INFO:tensorflow:LER = 0.86887777, loss = 2.527064 (21.740 sec)\n",
      "INFO:tensorflow:LER = 0.8199293, loss = 2.5495903 (22.223 sec)\n",
      "INFO:tensorflow:LER = 0.8635913, loss = 2.5565238 (22.230 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 386 into drive/My Drive/Tesis/repo/out/las_net/estimator/model.ckpt.\n",
      "INFO:tensorflow:LER = 0.9473477, loss = 2.5325577 (23.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.132296\n",
      "INFO:tensorflow:loss = 2.5538208, step = 386 (755.885 sec)\n",
      "INFO:tensorflow:LER = 0.79688644, loss = 2.543094 (20.613 sec)\n",
      "INFO:tensorflow:LER = 0.794585, loss = 2.5254486 (22.456 sec)\n",
      "INFO:tensorflow:LER = 0.97392327, loss = 2.533028 (22.069 sec)\n",
      "INFO:tensorflow:LER = 0.8515025, loss = 2.5438125 (21.569 sec)\n",
      "INFO:tensorflow:LER = 0.8674791, loss = 2.5366445 (22.376 sec)\n",
      "INFO:tensorflow:LER = 0.8719152, loss = 2.5341964 (22.298 sec)\n",
      "INFO:tensorflow:LER = 0.8848397, loss = 2.544953 (22.064 sec)\n",
      "INFO:tensorflow:LER = 0.9927265, loss = 2.5432847 (22.461 sec)\n",
      "INFO:tensorflow:LER = 0.8862837, loss = 2.5219185 (22.539 sec)\n",
      "INFO:tensorflow:LER = 0.918177, loss = 2.5313816 (22.894 sec)\n",
      "INFO:tensorflow:LER = 0.7643341, loss = 2.517264 (22.880 sec)\n",
      "INFO:tensorflow:LER = 0.8106412, loss = 2.5274243 (22.793 sec)\n",
      "INFO:tensorflow:LER = 0.785587, loss = 2.5370803 (22.711 sec)\n",
      "INFO:tensorflow:LER = 0.88880754, loss = 2.5195148 (22.737 sec)\n",
      "INFO:tensorflow:LER = 0.9582912, loss = 2.532067 (22.792 sec)\n",
      "INFO:tensorflow:LER = 1.0353695, loss = 2.5430417 (25.944 sec)\n",
      "INFO:tensorflow:LER = 0.87513375, loss = 2.5297468 (22.828 sec)\n",
      "INFO:tensorflow:LER = 0.8055148, loss = 2.5407836 (22.339 sec)\n",
      "INFO:tensorflow:LER = 0.85697854, loss = 2.5134504 (22.001 sec)\n",
      "INFO:tensorflow:LER = 0.8953784, loss = 2.5260568 (22.025 sec)\n",
      "INFO:tensorflow:LER = 0.86052614, loss = 2.5361571 (22.012 sec)\n",
      "INFO:tensorflow:LER = 0.82604086, loss = 2.503953 (22.210 sec)\n",
      "INFO:tensorflow:LER = 1.1548091, loss = 2.5199223 (21.909 sec)\n",
      "INFO:tensorflow:LER = 0.9052979, loss = 2.5075905 (22.256 sec)\n",
      "INFO:tensorflow:LER = 0.99528533, loss = 2.5108504 (22.175 sec)\n",
      "INFO:tensorflow:LER = 0.8792907, loss = 2.520233 (22.572 sec)\n",
      "INFO:tensorflow:LER = 0.82121354, loss = 2.5173285 (22.440 sec)\n",
      "INFO:tensorflow:LER = 0.8380016, loss = 2.5118668 (22.362 sec)\n",
      "INFO:tensorflow:LER = 0.96439445, loss = 2.5276048 (22.681 sec)\n",
      "INFO:tensorflow:LER = 0.92369306, loss = 2.5223947 (22.365 sec)\n",
      "INFO:tensorflow:LER = 0.8631677, loss = 2.5326974 (22.102 sec)\n",
      "INFO:tensorflow:LER = 0.88580483, loss = 2.530064 (21.903 sec)\n",
      "INFO:tensorflow:LER = 0.8473407, loss = 2.5149171 (22.518 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 486 into drive/My Drive/Tesis/repo/out/las_net/estimator/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 0.132563\n",
      "INFO:tensorflow:loss = 2.5198565, step = 486 (754.365 sec)\n",
      "INFO:tensorflow:LER = 1.067578, loss = 2.5198565 (27.571 sec)\n",
      "INFO:tensorflow:LER = 0.9318478, loss = 2.5231955 (22.561 sec)\n",
      "INFO:tensorflow:LER = 0.8209986, loss = 2.5077372 (22.331 sec)\n",
      "INFO:tensorflow:LER = 0.86785895, loss = 2.5265992 (22.772 sec)\n",
      "INFO:tensorflow:LER = 0.91200995, loss = 2.5244093 (22.360 sec)\n",
      "INFO:tensorflow:LER = 0.806151, loss = 2.5089753 (22.358 sec)\n",
      "INFO:tensorflow:LER = 1.045704, loss = 2.5106745 (22.426 sec)\n",
      "INFO:tensorflow:LER = 0.987529, loss = 2.4913716 (23.987 sec)\n",
      "INFO:tensorflow:LER = 0.9037205, loss = 2.524461 (22.029 sec)\n",
      "INFO:tensorflow:LER = 0.853492, loss = 2.515558 (22.157 sec)\n",
      "INFO:tensorflow:LER = 0.8131498, loss = 2.5024307 (22.750 sec)\n",
      "INFO:tensorflow:LER = 1.0592796, loss = 2.5148108 (22.248 sec)\n",
      "INFO:tensorflow:LER = 1.0717374, loss = 2.5128462 (22.312 sec)\n",
      "INFO:tensorflow:LER = 0.9380299, loss = 2.50207 (22.013 sec)\n",
      "INFO:tensorflow:LER = 0.9006034, loss = 2.5121212 (22.682 sec)\n",
      "INFO:tensorflow:LER = 1.0763592, loss = 2.5173657 (22.235 sec)\n",
      "INFO:tensorflow:LER = 0.8455661, loss = 2.5000012 (22.699 sec)\n",
      "INFO:tensorflow:LER = 0.8633779, loss = 2.5036952 (22.544 sec)\n",
      "INFO:tensorflow:LER = 0.95437723, loss = 2.495018 (22.243 sec)\n",
      "INFO:tensorflow:LER = 0.79406667, loss = 2.4829924 (22.238 sec)\n",
      "INFO:tensorflow:LER = 1.0111632, loss = 2.5032277 (21.932 sec)\n",
      "INFO:tensorflow:LER = 0.88220507, loss = 2.5019584 (22.679 sec)\n",
      "INFO:tensorflow:LER = 1.0100132, loss = 2.4968586 (22.258 sec)\n",
      "INFO:tensorflow:LER = 0.87641853, loss = 2.4884837 (21.957 sec)\n",
      "INFO:tensorflow:LER = 1.0040206, loss = 2.5048158 (22.372 sec)\n",
      "INFO:tensorflow:LER = 0.931266, loss = 2.5031211 (22.424 sec)\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    input_fn=lambda: data_input_fn(\n",
    "        filenames=train_files,\n",
    "        batch_size=train_batch_size,\n",
    "        parse_fn=Database.tfrecord_parse_dense_fn,\n",
    "        shuffle_buffer=10,\n",
    "        num_features=network_data.num_features,\n",
    "        num_epochs=train_epochs,\n",
    "        eos_id=LASLabel.EOS_INDEX,\n",
    "        sos_id=LASLabel.SOS_INDEX\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD4HmsIPvaLy",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "### Validación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SyGxknhxvTJ9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    input_fn=lambda: data_input_fn(\n",
    "        filenames=train_files,\n",
    "        batch_size=validate_batch_size,\n",
    "        parse_fn=Database.tfrecord_parse_dense_fn,\n",
    "        shuffle_buffer=1,\n",
    "        num_features=network_data.num_features,\n",
    "        eos_id=LASLabel.EOS_INDEX,\n",
    "        sos_id=LASLabel.SOS_INDEX\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebK_VwGpvkaG",
    "colab_type": "text"
   },
   "source": [
    "### Testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BcTE4yNhjtz9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "num_tests = 2\n",
    "\n",
    "predictions = model.predict(\n",
    "    input_fn=lambda: data_input_fn(\n",
    "        filenames=test_files,\n",
    "        batch_size=1,\n",
    "        parse_fn=Database.tfrecord_parse_dense_fn,\n",
    "        shuffle_buffer=1,\n",
    "        num_features=network_data.num_features,\n",
    "        eos_id=LASLabel.EOS_INDEX,\n",
    "        sos_id=LASLabel.SOS_INDEX\n",
    "    )\n",
    ")\n",
    "count = 0\n",
    "for item in predictions:\n",
    "  pred = item['sample_ids']\n",
    "#   print(item)\n",
    "  print(\"Predicted: \" + LASLabel.from_index(pred))\n",
    "  count += 1\n",
    "  # print(count)\n",
    "  if count >= num_tests:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "train_las_estimator.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
