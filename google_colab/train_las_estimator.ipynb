{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fwI55qLr3bL",
    "colab_type": "text"
   },
   "source": [
    "# Red LAS: Listen, Attend and Spell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp-sxdH_WdVL",
    "colab_type": "text"
   },
   "source": [
    "## Puesta a punto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiHlKPOlZHCS",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "\n",
    "### Instalación de paquetes necesarios\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "PtkPd7YoWZLl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!pip3 install python_speech_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn5bgHjdWxSM",
    "colab_type": "text"
   },
   "source": [
    "### Preparación del entorno para poder correr mis módulos importados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "yOE4tgZsW1et",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import sys\n",
    "sys.path.append('drive/My Drive/Tesis')\n",
    "sys.path.append('drive/My Drive/Tesis/repo')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_1mN3rHXqLT",
    "colab_type": "text"
   },
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh1DAAWCXygf",
    "colab_type": "text"
   },
   "source": [
    "### Importación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "itKOqreUX1gK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.utils.Database import Database\n",
    "from src.utils.LASLabel import LASLabel\n",
    "from src.utils.ProjectData import ProjectData\n",
    "import time\n",
    "from src.neural_network.LAS.LASNetData import LASNetData\n",
    "import pprint\n",
    "from src.Estimators.las.model_fn import model_fn\n",
    "from src.Estimators.las.data_input_fn import data_input_fn\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K73_jDd7X_CO",
    "colab_type": "text"
   },
   "source": [
    "### Definición de los hiperparámetros de la red\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ROoJRMZwX-at",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Load project data\n",
    "project_data = ProjectData()\n",
    "\n",
    "network_data = LASNetData()\n",
    "network_data.model_path = 'drive/My Drive/Tesis/repo/' + project_data.LAS_NET_MODEL_PATH\n",
    "network_data.checkpoint_path = 'drive/My Drive/Tesis/repo/' + project_data.LAS_NET_CHECKPOINT_PATH\n",
    "network_data.tensorboard_path = 'drive/My Drive/Tesis/repo/' + project_data.LAS_NET_TENSORBOARD_PATH\n",
    "\n",
    "network_data.num_classes = LASLabel.num_classes\n",
    "network_data.num_features = 494\n",
    "network_data.num_embeddings = 0\n",
    "network_data.sos_id = LASLabel.SOS_INDEX\n",
    "network_data.eos_id = LASLabel.EOS_INDEX\n",
    "\n",
    "network_data.beam_width = 0\n",
    "\n",
    "network_data.num_dense_layers_1 = 2\n",
    "network_data.num_units_1 = [400] * network_data.num_dense_layers_1\n",
    "network_data.dense_activations_1 = [tf.nn.relu] * network_data.num_dense_layers_1\n",
    "network_data.batch_normalization_1 = True\n",
    "network_data.keep_prob_1 = [0.7] * network_data.num_dense_layers_1\n",
    "network_data.kernel_init_1 = [tf.truncated_normal_initializer(mean=0, stddev=0.1)] * network_data.num_dense_layers_1\n",
    "network_data.bias_init_1 = [tf.zeros_initializer()] * network_data.num_dense_layers_1\n",
    "\n",
    "network_data.listener_num_layers = 1\n",
    "network_data.listener_num_units = [256] * network_data.listener_num_layers\n",
    "network_data.listener_activation_list = [tf.nn.tanh] * network_data.listener_num_layers\n",
    "network_data.listener_keep_prob_list = [0.8] * network_data.listener_num_layers\n",
    "\n",
    "network_data.num_dense_layers_2 = 1\n",
    "network_data.num_units_2 = [300]\n",
    "network_data.dense_activations_2 = [tf.nn.relu] * network_data.num_dense_layers_2\n",
    "network_data.batch_normalization_2 = True\n",
    "network_data.keep_prob_2 = [0.7] * network_data.num_dense_layers_2\n",
    "network_data.kernel_init_2 = [tf.truncated_normal_initializer(mean=0, stddev=0.1)] * network_data.num_dense_layers_2\n",
    "network_data.bias_init_2 = [tf.zeros_initializer()] * network_data.num_dense_layers_2\n",
    "\n",
    "network_data.attention_type = 'luong'       # 'luong', 'bahdanau'\n",
    "network_data.attention_num_layers = 1\n",
    "network_data.attention_size = None\n",
    "network_data.attention_units = 256\n",
    "network_data.attention_activation = tf.nn.tanh\n",
    "network_data.attention_keep_prob = 0.8\n",
    "\n",
    "network_data.kernel_regularizer = 0.0\n",
    "network_data.sampling_probability = 0.2\n",
    "\n",
    "network_data.optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "pprint.pprint(network_data.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi_FGeToYX5k",
    "colab_type": "text"
   },
   "source": [
    "### Configuración de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VnVktYkdYct3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model_dir = 'drive/My Drive/Tesis/repo/out/las_net/estimator/'\n",
    "\n",
    "base_path = 'drive/My Drive/Tesis/repo/data/tfrecords/librispeech/las/ds_dataset/'\n",
    "\n",
    "index_files = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "train_files = ['train_database_{}.tfrecords'.format(item) for item in index_files]\n",
    "val_files = ['test_database_1.tfrecords', 'test_database_2.tfrecords']\n",
    "test_files = ['test_database_2.tfrecords']\n",
    "\n",
    "train_files = list(map(lambda x: base_path + x, train_files))\n",
    "val_files = list(map(lambda x: base_path + x, val_files))\n",
    "test_files = list(map(lambda x: base_path + x, test_files))\n",
    "\n",
    "train_batch_size = 100\n",
    "train_epochs = 1000\n",
    "\n",
    "validate_batch_size = 100\n",
    "\n",
    "restore_run = True\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=model_dir,\n",
    "    save_checkpoints_steps=100,\n",
    "    save_summary_steps=100,\n",
    "    log_step_count_steps=100)\n",
    "\n",
    "\n",
    "model = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    params=network_data.as_dict(),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if not restore_run:\n",
    "    shutil.rmtree(model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q28RImgUvX60",
    "colab_type": "text"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rYcvBQsDZe-G",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    input_fn=lambda: data_input_fn(\n",
    "        filenames=train_files,\n",
    "        batch_size=train_batch_size,\n",
    "        parse_fn=Database.tfrecord_parse_dense_fn,\n",
    "        shuffle_buffer=10,\n",
    "        num_features=network_data.num_features,\n",
    "        num_epochs=train_epochs,\n",
    "        eos_id=LASLabel.EOS_INDEX,\n",
    "        sos_id=LASLabel.SOS_INDEX\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD4HmsIPvaLy",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "### Validación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SyGxknhxvTJ9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    input_fn=lambda: data_input_fn(\n",
    "        filenames=train_files,\n",
    "        batch_size=validate_batch_size,\n",
    "        parse_fn=Database.tfrecord_parse_dense_fn,\n",
    "        shuffle_buffer=1,\n",
    "        num_features=network_data.num_features,\n",
    "        eos_id=LASLabel.EOS_INDEX,\n",
    "        sos_id=LASLabel.SOS_INDEX\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebK_VwGpvkaG",
    "colab_type": "text"
   },
   "source": [
    "### Testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BcTE4yNhjtz9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "num_tests = 10\n",
    "\n",
    "predictions = model.predict(\n",
    "    input_fn=lambda: data_input_fn(\n",
    "        filenames=test_files,\n",
    "        batch_size=1,\n",
    "        parse_fn=Database.tfrecord_parse_dense_fn,\n",
    "        shuffle_buffer=1,\n",
    "        num_features=network_data.num_features,\n",
    "        eos_id=LASLabel.EOS_INDEX,\n",
    "        sos_id=LASLabel.SOS_INDEX\n",
    "    )\n",
    ")\n",
    "count = 0\n",
    "for item in predictions:\n",
    "  pred = item['sample_ids']\n",
    "  print(\"Predicted: \" + LASLabel.from_index(pred))\n",
    "  count += 1\n",
    "  if count >= num_tests:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copia de train_las_estimator.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
